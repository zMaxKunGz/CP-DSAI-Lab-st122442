{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Modify the Decision Tree scratch code in our lecture such that:\n",
    "- Modify the scratch code so it can accept an hyperparameter <code>max_depth</code>, in which it will continue create the tree until max_depth is reached.</li>\n",
    "- Put everything into a class <code>DecisionTree</code>.  It should have at least two methods, <code>fit()</code>, and <code>predict()</code>\n",
    "- Load the iris data and try with your class</li>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "#To help with our implementation, we create a class Node\n",
    "class Node:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class DescissionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def find_split(self, X, y, n_classes):\n",
    "        \"\"\" Find split where children has lowest impurity possible\n",
    "        in condition where the purity should also be less than the parent,\n",
    "        if not, stop.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        if n_samples <= 1:\n",
    "            return None, None\n",
    "        \n",
    "        #so it will not have any warning about \"referenced before assignments\"\n",
    "        feature_ix, threshold = None, None\n",
    "        \n",
    "        # Count of each class in the current node.\n",
    "        sample_per_class_parent = [np.sum(y == c) for c in range(n_classes)] #[2, 2]\n",
    "        \n",
    "        # Gini of parent node.\n",
    "        best_gini = 1.0 - sum((n / n_samples) ** 2 for n in sample_per_class_parent)\n",
    "\n",
    "        # Loop through all features.\n",
    "        for feature in range(n_features):\n",
    "            sample_sorted = sorted(X[:, feature]) #[2, 3, 10, 19]\n",
    "            sort_idx = np.argsort(X[:, feature])\n",
    "            y_sorted = y[sort_idx] #[0, 0, 1, 1]\n",
    "                    \n",
    "            sample_per_class_left = [0] * n_classes   #[0, 0]\n",
    "            \n",
    "            sample_per_class_right = sample_per_class_parent.copy() #[2, 2]\n",
    "            \n",
    "            for i in range(1, n_samples): #1 to 3 (excluding 4)\n",
    "                #the class of that sample\n",
    "                c = y_sorted[i - 1]  #[0]\n",
    "                \n",
    "                #put the sample to the left\n",
    "                sample_per_class_left[c] += 1  #[1, 0]\n",
    "                            \n",
    "                #take the sample out from the right  [1, 2]\n",
    "                sample_per_class_right[c] -= 1\n",
    "                \n",
    "                gini_left = 1.0 - sum(\n",
    "                    (sample_per_class_left[x] / i) ** 2 for x in range(n_classes)\n",
    "                )\n",
    "                            \n",
    "                #we divided by n_samples - i since we know that the left amount of samples\n",
    "                #since left side has already i samples\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (sample_per_class_right[x] / (n_samples - i)) ** 2 for x in range(n_classes)\n",
    "                )\n",
    "\n",
    "                #weighted gini\n",
    "                weighted_gini = ((i / n_samples) * gini_left) + ( (n_samples - i) /n_samples) * gini_right\n",
    "\n",
    "                # in case the value are the same, we do not split\n",
    "                # (both have to end up on the same side of a split).\n",
    "                if sample_sorted[i] == sample_sorted[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    feature_ix = feature\n",
    "                    threshold = (sample_sorted[i] + sample_sorted[i - 1]) / 2  # midpoint\n",
    "\n",
    "        #return the feature number and threshold \n",
    "        #used to find best split\n",
    "        return feature_ix, threshold\n",
    "    \n",
    "    def fit(self, Xtrain, ytrain, n_classes, depth=0, ):  \n",
    "        n_samples, n_features = Xtrain.shape\n",
    "        num_samples_per_class = [np.sum(ytrain == i) for i in range(n_classes)]\n",
    "        #predicted class using the majority of sample class\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        \n",
    "        #define the parent node\n",
    "        node = Node(\n",
    "            gini = 1 - sum((np.sum(ytrain == c) / n_samples) ** 2 for c in range(n_classes)),\n",
    "            predicted_class=predicted_class,\n",
    "            num_samples = ytrain.size,\n",
    "            num_samples_per_class = num_samples_per_class,\n",
    "            )\n",
    "            \n",
    "        if self.max_depth is not None and depth == self.max_depth:\n",
    "            return node\n",
    "        else:\n",
    "            feature, threshold = self.find_split(Xtrain, ytrain, n_classes)\n",
    "            if feature is not None:\n",
    "                #take all the indices that is less than threshold\n",
    "                indices_left = Xtrain[:, feature] < threshold\n",
    "                X_left, y_left = Xtrain[indices_left], ytrain[indices_left]\n",
    "\n",
    "                #tilde for negation\n",
    "                X_right, y_right = Xtrain[~indices_left], ytrain[~indices_left]\n",
    "\n",
    "                #take note for later decision\n",
    "                node.feature_index = feature\n",
    "                node.threshold = threshold\n",
    "                node.left = self.fit(X_left, y_left, n_classes, depth + 1)\n",
    "                node.right = self.fit(X_right, y_right, n_classes, depth + 1)\n",
    "            return node\n",
    "\n",
    "    def predict(self, X, tree):\n",
    "        first_node = tree\n",
    "        predicted = []\n",
    "        for i in range(X.shape[0]):\n",
    "            tree = first_node\n",
    "            while tree.left:\n",
    "                if X[i, tree.feature_index] < tree.threshold:\n",
    "                    tree = tree.left\n",
    "                else:\n",
    "                    tree = tree.right\n",
    "            predicted.append(tree.predicted_class)\n",
    "        return predicted"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "model = DescissionTree(max_depth=10)\n",
    "tree = model.fit(X_train, y_train, 3)\n",
    "predicted = model.predict(X_test, tree)\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.85      0.92        13\n",
      "           2       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "1df8770f36cccaa28b49186283820102a7be0be7912bde98ce292c19ce2372ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}